{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Data from Google Drive\n",
    "import gdown\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1o_EEumVnswul9MVsrdDwBch5rt7JTr0m\n",
      "To: c:\\Users\\Steven\\Documents\\Projects\\ss24-capstone-team23-datallah-nkitts-steveso\\temporary_files\\merged.csv\n",
      "100%|██████████| 438k/438k [00:00<00:00, 5.92MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../temporary_files/merged.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save data to the temporary folder\n",
    "merged_data_file_id = '1o_EEumVnswul9MVsrdDwBch5rt7JTr0m'\n",
    "merged_data_url = f'https://drive.google.com/uc?id={merged_data_file_id}'\n",
    "output = '../temporary_files/merged.csv'\n",
    "gdown.download(merged_data_url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load merged data into DataFrame\n",
    "merged_df = pd.read_csv('../temporary_files/merged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Correclation Analysis\n",
    "Find out what features has very strong/ very weak correlation to the precitor(ZHVI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZHVI                           1.000000\n",
       "NewHomePermits                 0.112964\n",
       "Population_In_Housing_Units    0.317605\n",
       "Owner_Occupied_Population      0.190940\n",
       "Renter-Occupied-Population     0.431823\n",
       "                                 ...   \n",
       "tot_emp                        0.381415\n",
       "a_mean                         0.665366\n",
       "a_median                       0.574697\n",
       "h_mean                         0.665444\n",
       "h_median                       0.574689\n",
       "Name: ZHVI, Length: 83, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = merged_df.drop(['Date', 'City'], axis=1).corr()\n",
    "\n",
    "# Check the correlation between features and the target variable (ZHVI). Highly correlated features might not add additional value.\n",
    "corr_matrix.loc['ZHVI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages for Feature Importance Analysis\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.base import BaseEstimator, RegressorMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process the data;\n",
    "def preprocess_data(df, window=3):\n",
    "    # Separate train and test data (80% train, 20% test)\n",
    "    split_index = int(len(df) * 0.8)\n",
    "    train_df = df.iloc[:split_index]\n",
    "    test_df = df.iloc[split_index:]\n",
    "\n",
    "    # Scale the features using MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    train_scaled = scaler.fit_transform(train_df.drop(['Date', 'City'], axis=1))\n",
    "    test_scaled = scaler.transform(test_df.drop(['Date', 'City'], axis=1))\n",
    "\n",
    "    # Create sequences of 12 months for training\n",
    "    X_train, y_train = [], []\n",
    "    for i in range(window, len(train_scaled)):\n",
    "        X_train.append(train_scaled[i-window:i])\n",
    "        y_train.append(train_scaled[i, 0])  # ZHVI is the first column\n",
    "\n",
    "    X_test, y_test = [], []\n",
    "    for i in range(window, len(test_scaled)):\n",
    "        X_test.append(test_scaled[i-window:i])\n",
    "        y_test.append(test_scaled[i, 0])  # ZHVI is the first column\n",
    "\n",
    "    return np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test), scaler\n",
    "\n",
    "# Function to create and train LSTM\n",
    "def create_and_train_lstm(X_train, y_train, epochs=100, batch_size=32):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(LSTM(units=50, return_sequences=True))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Function to make predictions and inverse scale them\n",
    "def make_predictions(model, X, scaler):\n",
    "    predictions = model.predict(X)\n",
    "    predictions = scaler.inverse_transform(np.hstack((predictions, np.zeros((predictions.shape[0], X.shape[2] - 1)))))\n",
    "    return predictions[:, 0]  # Only return the ZHVI predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
